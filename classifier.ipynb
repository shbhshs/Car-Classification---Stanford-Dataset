{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\nimport torch\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch import nn, optim\n\nfrom torchvision import transforms, models\nfrom torchvision.utils import make_grid\n\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score\nfrom scipy.io import loadmat\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../input/'))\npath_devkit = '../input/devkit-car-dataset/'\npath_train_img = '../input/stanford-cars-dataset/cars_train/cars_train/'\npath_test_img = '../input/stanford-cars-dataset/cars_test/cars_test/'\n\nNUM_CLASSES = 196\nIMG_SIZE = 224\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets store the information in the dataframe\nmat = loadmat(path_devkit+'cars_meta.mat')\n\nclasses = []\nfor C in mat['class_names'][0]:\n    classes.append(C[0])\nclasses = pd.DataFrame(classes,columns=['class_name'])\n\n#blankidx = [''] * len(classes)\n#classes.index = blankidx\nclasses.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets store the data in the dataFrame\nmat = loadmat(path_devkit+'cars_train_annos.mat')\ntrain_df = []\nfor row in mat['annotations'][0]:\n    train_df.append([row[0][0][0],    # min x\n                     row[1][0][0],    # max x\n                     row[2][0][0],    # min y\n                     row[3][0][0],    # max y\n                     row[4][0][0],    # class\n                     row[5][0]])   # file name\n\n\ntrain_df = pd.DataFrame(train_df, columns=['min_x', 'min_y', 'max_x', 'max_y','class_name', 'file_name'])\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets store the test data in the dataFrame\nmat = loadmat(path_devkit+'cars_test_annos_withlabels.mat')\ntest_df = []\nfor row in mat['annotations'][0]:\n    test_df.append([row[0][0][0],    # min x\n                    row[1][0][0],    # max x\n                    row[2][0][0],    # min y\n                    row[3][0][0],    # max y\n                    row[4][0][0],    # class\n                    row[5][0]])      # file name\n\ntest_df = pd.DataFrame(test_df, columns=['min_x', 'min_y', 'max_x', 'max_y', 'class_name', 'file_name'])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now split the train dataset into val and train\nval_df = train_df.sample(frac=0.2, random_state=RANDOM_SEED)\ntrain_df = train_df.drop(val_df.index)\n\nprint('Training set: {}\\nValidation set: {}'.format(train_df.shape, val_df.shape))\n\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = plt.imread(path_train_img+'00001.jpg')\nplt.imshow(img)\nprint(classes.iloc[13])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do some EDA\ntrain_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(train_df.info())\n# types={'min_x':np.int16, 'min_y':np.int16, 'max_x':np.int16, 'max_y':np.int16,'class_name':np.int8}\n# train_df = train_df.astype(types)\n# print(train_df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CarDataset(Dataset):\n    def __init__(self,df, classes, transforms=None, mode='train'):\n        self.df = train_df\n        self.classes = classes\n        self.transforms = transforms\n        self.mode = mode\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        if self.mode == 'train':\n            img_name = self.df.iloc[index]['file_name']\n            img = Image.open(path_train_img+img_name).convert('RGB')   # to create images with 3 channels\n#             create one hot vector for the label\n            label = np.zeros(196)\n            label[self.df.iloc[index]['class_name'] - 1] = 1\n\n        # add test part later\n        \n\n        #crop image\n        img = img.crop((self.df.iloc[index]['min_x'],\n                        self.df.iloc[index]['min_y'],\n                        self.df.iloc[index]['max_x'],\n                        self.df.iloc[index]['max_y']))\n        \n        if self.transforms is not None:\n            img =  self.transforms(img)\n            \n            return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((224,224)),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ToTensor()])\n                                # normalisation later\n\ntrain_dataset = CarDataset(train_df, classes, transforms = transform)\ntrain_generator = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n# validation data generator\nval_dataset = CarDataset(val_df, classes, transforms = transform)\nval_generator = DataLoader(val_dataset, batch_size=32, shuffle=True)\n\n# test data generator\ntest_dataset = CarDataset(test_df, classes, transforms = transform)\ntest_generator = DataLoader(test_dataset, batch_size=32, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, labels = next(iter(train_generator))\nprint('Image shape: {}\\nLabels shape: {}'.format(images.shape, labels.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(num=None, figsize=(8, 8), dpi=100, facecolor='w', edgecolor='k')\ngrid = make_grid(images,nrow=8)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.axis('off')\n#plt.title(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# network\nmodel = models.densenet121(pretrained=True)\nmodel.classifier = nn.Sequential(nn.Linear(1024,NUM_CLASSES),\n                                 nn.Sigmoid())                    # need to change this to softmax as we also need to predict the confidence score.\n\n\n# class customDensenet121(nn.Module):\n#     def __init__(self,num_classes):\n#         super(customDensenet121,self).__init__()\n#         self.features = nn.Sequential(*list(model.features.children()))\n#         self.classifier = nn.Sequential(nn.Linear(1024,num_classes),\n#                                         nn.Sigmoid())\n        \n#     def forward(self, x):\n#         x = self.features(x)\n#         x = x.view(x.size(0),-1)\n#         x = self.classifier(x)\n#         return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_gpu = False\nif torch.cuda.is_available:\n    model.cuda()\n    use_gpu = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper functions\ndef accuracy(y, pred_y, dim=1):\n    _, y_index = torch.max(y, dim=dim)\n    _, pred_y_index = torch.max(pred_y, dim=dim)\n    num_correct = torch.sum(pred_y_index==y_index)\n    acc = num_correct.item()/len(y)\n    return acc\n\n\ndef precision(y, pred_y, dim=1):\n    _, y_index = torch.max(y, dim=dim)\n    _, pred_y_index = torch.max(pred_y, dim=dim)\n    precision = precision_score(y_index.numpy(), pred_y_index.numpy(), average='micro')\n    return precision\n\ndef recall(y, pred_y, dim=1):\n    _, y_index = torch.max(y, dim=dim)\n    _, pred_y_index = torch.max(pred_y, dim=dim)\n    recall = recall_score(y_index.numpy(), pred_y_index.numpy(),average='micro')\n    return recall\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, epochs, train_generator, val_generator, use_gpu, optimizer, criterion):\n    train_loss, val_loss = [],[]\n    train_acc, val_acc = [], []\n    for epoch in range(epochs):\n        running_loss = 0\n        for images, labels in train_generator:\n            if use_gpu:\n                labels = labels.cuda()\n                labels = labels.type(torch.cuda.FloatTensor)\n                images = images.cuda()\n            \n            optimizer.zero_grad()\n            output = model(images)\n            loss = criterion(output,labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n        else:\n            acc = 0\n            prec = 0\n            rcl = 0\n            test_loss = 0\n            with torch.no_grad():\n                model.eval()\n                for images, labels in val_generator:\n                    if use_gpu:\n                        images = images.cuda()\n                        labels = labels.cuda()\n                        labels = labels.type(torch.cuda.FloatTensor)\n                        \n                    output = model(images)\n                    test_loss += criterion(output, labels)\n                    output = output.cpu()\n                    labels = labels.cpu()\n                    acc += accuracy(labels, output)\n                    prec += precision(labels, output)\n                    rcl += recall(labels, output)\n                    # add metrics here like accuracy, precision and recall as mentioned in the problem statement\n                    # ps = torch.exp(logps)\n        \n        if (epoch+1) % 5 == 0:\n            torch.save(model.state_dict(), 'checkpoint_epoch_{}.pth'.format(epoch+1))\n            \n        train_loss.append(running_loss/len(train_generator))\n        val_loss.append(test_loss/len(val_generator))\n        val_acc.append(acc/len(val_generator))\n        model.train()\n        \n        print('Epoch: {}/{}'.format(epoch+1,epochs),\n              'Training Loss: {}\\t\\tValidation Loss: {}'.format(train_loss[-1], val_loss[-1]),\n              'Val Accuracy:  {}'.format(val_acc[-1]),\n              'Val Precision: {}'.format(prec/len(val_generator)),\n              'Val Recall:    {}'.format(rcl/len(val_generator)),sep='\\n')\n    \n    return train_loss,val_loss,val_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 2\n\ncriterion = nn.BCELoss()\noptimizer = optim.Adam([{'params': model.features.parameters()},\n                     {'params': model.classifier.parameters(), 'lr': 0.001}],\n                    lr=0.0001)\n\ntrain_losses, val_losses, val_acc = train_model(model,epochs,train_generator, val_generator, \n                                       use_gpu, optimizer, criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_losses, label='Training loss')\nplt.plot(val_losses, label='Validation loss')\nplt.legend(frameon=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(val_acc, label='Val Accuracy')\nplt.legend(frameon=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_accuracy(model, test_generator, use_gpu):\n    acc = 0\n    model.eval()\n    for images,labels in test_generator:\n        if use_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            labels = labels.type(torch.cuda.FloatTensor)\n            \n        output = model(images)\n        acc += accuracy(output, labels)\n        \n    return(acc/len(test_generator))\n\n# call \ntest_accuracy(model, test_generator, use_gpu)    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}